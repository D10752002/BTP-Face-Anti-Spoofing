{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install mtcnn\n",
    "# !pip install tensorflow\n",
    "# !pip install facenet-pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing OULU-NPU into image frames for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "import random\n",
    "import string\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "# from imutils import face_utils\n",
    "import matplotlib.pyplot as plt\n",
    "# from mtcnn.mtcnn import MTCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# face_cascade = cv2.CascadeClassifier('./haarcascade_frontalface_default.xml')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_face(img):\n",
    "#     # Convert to grayscale \n",
    "#     gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  \n",
    "  \n",
    "#     # Detect the faces  \n",
    "#     faces = face_cascade.detectMultiScale(gray, 1.3, 4)  \n",
    "    \n",
    "#     # Draw rectangle around the faces and crop the faces\n",
    "#     for (x, y, w, h) in faces:\n",
    "#         faces = img[y:y + h, x:x + w]\n",
    "        \n",
    "#     return faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_face(img):\n",
    "#     # Detect faces\n",
    "#     results = detector.detect_faces(img)\n",
    "    \n",
    "#     faces = []\n",
    "#     for result in results:\n",
    "#         x, y, w, h = result['box']\n",
    "#         face = img[y:y+h, x:x+w]\n",
    "#         faces.append(face)\n",
    "    \n",
    "#     return faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_face(img):\n",
    "#     face_cascade = cv2.CascadeClassifier('./haarcascade_frontalface_default.xml')  \n",
    "#     gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  \n",
    "#     faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "    \n",
    "#     face_images = []\n",
    "#     for (x, y, w, h) in faces:\n",
    "#         face = img[y:y+h, x:x+w]\n",
    "#         face_images.append(face)\n",
    "    \n",
    "#     return face_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_face_and_save(image_path, output_path):\n",
    "#     # Load the image\n",
    "#     img = cv2.imread(image_path)\n",
    "    \n",
    "#     # Convert to grayscale\n",
    "#     gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "  \n",
    "#     # Detect the faces\n",
    "#     faces = face_cascade.detectMultiScale(gray, 1.3, 4)\n",
    "    \n",
    "#     # Draw rectangle around the faces and save the image\n",
    "#     for (x, y, w, h) in faces:\n",
    "#         cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)  # Draw a green rectangle around the face\n",
    "        \n",
    "#     # Save the image with rectangles\n",
    "#     cv2.imwrite(output_path, img)\n",
    "    \n",
    "#     return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_face_and_save(image_path, output_path):\n",
    "#     # Load the image\n",
    "#     img = cv2.imread(image_path)\n",
    "    \n",
    "#     # Initialize the MTCNN detector\n",
    "#     detector = MTCNN()\n",
    "    \n",
    "#     # Detect faces\n",
    "#     results = detector.detect_faces(img)\n",
    "    \n",
    "#     # Draw rectangle around the faces and save the image\n",
    "#     for result in results:\n",
    "#         x, y, w, h = result['box']\n",
    "#         cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)  # Draw a green rectangle around the face\n",
    "    \n",
    "#     # Save the image with rectangles\n",
    "#     cv2.imwrite(output_path, img)\n",
    "    \n",
    "#     return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract_face_and_save('./test_img.jpg', 'test_img_output_face_bound.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('./haarcascade_frontalface_default.xml')\n",
    "\n",
    "def extract_face(img, eye_coords):\n",
    "    # Get eye coordinates\n",
    "    x_eye_left, y_eye_left, x_eye_right, y_eye_right = map(int, eye_coords)\n",
    "    # print(x_eye_left, y_eye_left, x_eye_right, y_eye_right)\n",
    "    # Calculate the approximate size of the face using the distance between the eyes\n",
    "    face_width = abs(x_eye_left - x_eye_right) * 3.5  # Adjust factor as needed\n",
    "    face_height = face_width * 1.2  # Adjust factor as needed\n",
    "\n",
    "    # Calculate the center point between the eyes\n",
    "    center_x = (x_eye_left + x_eye_right) // 2\n",
    "    center_y = (y_eye_left + y_eye_right) // 2\n",
    "    # Define bounding box around the face\n",
    "    # print(int(center_x - face_width // 2), int(center_x + face_width // 2))\n",
    "    # print(int(center_y - face_height // 2), int(center_y + face_height // 2))\n",
    "    \n",
    "    x1 = max(0, int(center_x - face_width // 2))\n",
    "    y1 = max(0, int(center_y - face_height // 2))\n",
    "    x2 = min(img.shape[1], int(center_x + face_width // 2))\n",
    "    y2 = min(img.shape[0], int(center_y + face_height // 2))\n",
    "    if x1 < x2 and y1 < y2:\n",
    "        # Get the region around the eyes\n",
    "        # print(x1, y1, x2, y2)\n",
    "        eyes_region = img[y1:y2, x1:x2]\n",
    "        # Detect faces in the eyes region\n",
    "        gray_eyes = cv2.cvtColor(eyes_region, cv2.COLOR_BGR2GRAY)\n",
    "        def try_detect(scale_factor, min_neighbors):\n",
    "            try:\n",
    "                faces = face_cascade.detectMultiScale(gray_eyes, scale_factor, min_neighbors)\n",
    "                if len(faces) > 0:\n",
    "                    (fx, fy, fw, fh) = faces[0]\n",
    "\n",
    "                    fx1 = x1 + fx\n",
    "                    fy1 = y1 + fy\n",
    "                    fx2 = fx1 + fw\n",
    "                    fy2 = fy1 + fh\n",
    "\n",
    "                    face = img[fy1:fy2, fx1:fx2]\n",
    "\n",
    "                    return face\n",
    "\n",
    "            except Exception as e:\n",
    "                pass\n",
    "\n",
    "        # Try detecting with different parameters\n",
    "        face = try_detect(1.2, 3)\n",
    "        if face is None or face.shape[0] * face.shape[1] < 1e5:\n",
    "            face = try_detect(1.1, 5)\n",
    "        if face is None or face.shape[0] * face.shape[1] < 1e5:\n",
    "            face = try_detect(1.1, 3)\n",
    "        if face is None or face.shape[0] * face.shape[1] < 1e5:\n",
    "            face = try_detect(1.3, 4)\n",
    "        if face is None or face.shape[0] * face.shape[1] < 1e5:\n",
    "            face = try_detect(1.5, 4)\n",
    "        if face is not None:\n",
    "            return face\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "def read_eye_coordinates(txt_file):\n",
    "    with open(txt_file, 'r') as file:\n",
    "        eye_coords = [line.strip().split(',') for line in file]\n",
    "\n",
    "    return eye_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_multiple_videos(input_filenames, output_path, resize):\n",
    "    i = 0  # Counter of first video\n",
    "    abnormal_total_count=0\n",
    "    no_detections_total_count=0\n",
    "    for input_filename in tqdm(input_filenames, desc='Processing Videos'):\n",
    "        # print(f\"\\rFile: {i}\")\n",
    "        img_name = 'client'\n",
    "        pattern = input_filename.split('/')\n",
    "        last_substring = pattern[-1]  # Get the last substring after splitting by '/'\n",
    "        # print(last_substring)\n",
    "        f_name = last_substring.split('_')  # Split the last substring by underscores\n",
    "        if len(f_name) >= 4:  # Ensure there are at least 4 parts in the split\n",
    "            img_name = '_'.join(f_name[:3])  # Join the first three parts with underscores\n",
    "\n",
    "        # print(img_name)  # Print or use img_name as needed\n",
    "\n",
    "        # Get the eye coordinates for this video\n",
    "        eye_coordinates = read_eye_coordinates(input_filename.replace('.avi', '.txt'))\n",
    "\n",
    "        abnormal_count=0\n",
    "        no_detection_count=0\n",
    "        # Open video capture\n",
    "        cap = cv2.VideoCapture(input_filename)\n",
    "        sec_count = 0\n",
    "\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            if ret:\n",
    "                try:\n",
    "                    eye_coords = eye_coordinates[sec_count]\n",
    "                    cropped_faces = extract_face(frame, eye_coords[1:])  # Exclude num_frame\n",
    "                    if cropped_faces is None:\n",
    "                        # print('No detection')\n",
    "                        sec_count +=1\n",
    "                        no_detection_count +=1\n",
    "                        continue\n",
    "                    if cropped_faces.shape[0]*cropped_faces.shape[1] < 1e5:\n",
    "                        # print('abnormal detection')\n",
    "                        sec_count +=1\n",
    "                        abnormal_count +=1\n",
    "                        continue\n",
    "                    cropped_faces = cv2.resize(cropped_faces, (resize, resize))\n",
    "                    write_path = output_path + f'{img_name}_{eye_coords[0]}_{i}.png'  # Use num_frame\n",
    "                    cv2.imwrite(write_path, cropped_faces)\n",
    "                    i += 1\n",
    "                    sec_count += 1\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing frame {sec_count}: {e}\")\n",
    "                    sec_count += 1\n",
    "            else:\n",
    "                break\n",
    "\n",
    "\n",
    "        cap.release()\n",
    "        if abnormal_count!=0 or no_detection_count!=0:\n",
    "            print(last_substring)\n",
    "        if abnormal_count!=0:\n",
    "            print(f'abnormal detections: {abnormal_count}')\n",
    "        if no_detection_count!=0:\n",
    "            print(f'no detections: {no_detection_count}')\n",
    "        abnormal_total_count +=abnormal_count\n",
    "        no_detections_total_count +=no_detection_count\n",
    "    print(f'Total abnormal detections count: {abnormal_total_count}')\n",
    "    print(f'Total No detections count: {no_detections_total_count}')\n",
    "\n",
    "    return i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # START CAPTURING VIDEOS\n",
    "\n",
    "# def extract_multiple_videos(input_filenames,output_path,img_class,frame_rate, resize):\n",
    "#     \"\"\"Extract video files into sequence of images.\n",
    "#        input_filenames is a list for video file names\"\"\"\n",
    "\n",
    "#     i = 0  # Counter of first video\n",
    "\n",
    "#     # Iterate file names:\n",
    "#     for input_filename in input_filenames:\n",
    "        \n",
    "#         img_name = 'client'\n",
    "#         pattern = input_filename.split('/')\n",
    "#         last_substring = pattern[-1]  # Get the last substring after splitting by '/'\n",
    "#         print(last_substring)\n",
    "#         f_name = last_substring.split('_')  # Split the last substring by underscores\n",
    "#         if len(f_name) >= 4:  # Ensure there are at least 4 parts in the split\n",
    "#             img_name = '_'.join(f_name[:3])  # Join the first three parts with underscores\n",
    "    \n",
    "#         print(img_name)  # Print or use img_name as needed\n",
    "        \n",
    "#         # print('the image will be named as:', img_name)\n",
    "        \n",
    "        \n",
    "#         sec_count = 0\n",
    "#         cap = cv2.VideoCapture(input_filename)\n",
    "#         cap.set(cv2.CAP_PROP_POS_MSEC,(sec_count*frame_rate))\n",
    "\n",
    "#         # Keep iterating break\n",
    "#         while True:\n",
    "#             ret, frame = cap.read()  # Read frame from first video\n",
    "\n",
    "#             if ret:\n",
    "#                 try:\n",
    "#                     cropped_faces = extract_face(frame)\n",
    "#                     cropped_faces = cv2.resize(cropped_faces,(resize,resize))\n",
    "#                     write_path = output_path + f'{img_name}_{i}_{img_class}.png'\n",
    "#                     cv2.imwrite(write_path, cropped_faces)  # Write frame to JPEG file (1.jpg, 2.jpg, ...)\n",
    "#                     i += 1 # Advance file counter\n",
    "#                     sec_count += 1\n",
    "#                 except:\n",
    "#                     pass\n",
    "#             else:\n",
    "#                 # Break the interal loop when res status is False.\n",
    "#                 break\n",
    "\n",
    "#             delay = int(1000 / frame_rate)  # Calculate the delay based on the actual frame rate\n",
    "#             cv2.waitKey(delay)\n",
    "\n",
    "#         cap.release() #Release must be inside the outer loop\n",
    "#     return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from facenet_pytorch import MTCNN\n",
    "# import torch\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# mtcnn = MTCNN(keep_all=True, device=device)  # Initialize the detector outside the function\n",
    "\n",
    "# def extract_face_using_eyes(img, eye_coords):\n",
    "#     # Use eye coordinates to define region of interest (ROI) for face detection\n",
    "#     x_eye_left, y_eye_left, x_eye_right, y_eye_right = eye_coords\n",
    "    \n",
    "#     # Define the region around the eyes for face detection\n",
    "#     roi_x = min(x_eye_left, x_eye_right)\n",
    "#     roi_y = min(y_eye_left, y_eye_right)\n",
    "#     roi_w = max(x_eye_left, x_eye_right) - roi_x\n",
    "#     roi_h = max(y_eye_left, y_eye_right) - roi_y\n",
    "    \n",
    "#     # Extract the region for face detection\n",
    "#     roi = img[roi_y:roi_y+roi_h, roi_x:roi_x+roi_w]\n",
    "    \n",
    "#     # Detect faces in the ROI\n",
    "#     boxes, probs = mtcnn.detect(roi)\n",
    "    \n",
    "#     # Adjust the face coordinates to the original image space\n",
    "#     if boxes is not None:\n",
    "#         boxes[:, [0, 2]] += roi_x\n",
    "#         boxes[:, [1, 3]] += roi_y\n",
    "    \n",
    "#     return boxes\n",
    "\n",
    "# def extract_multiple_videos_with_eyes(input_filenames, output_path, img_class, frame_rate, resize):\n",
    "#     i = 0  # Counter of first video\n",
    "\n",
    "#     for input_filename in input_filenames:\n",
    "#         img_name = 'client'\n",
    "#         pattern = input_filename.split('/')\n",
    "#         last_substring = pattern[-1]\n",
    "#         f_name = last_substring.split('_')\n",
    "#         if len(f_name) >= 4:\n",
    "#             img_name = '_'.join(f_name[:3])\n",
    "    \n",
    "#         sec_count = 0\n",
    "#         cap = cv2.VideoCapture(input_filename)\n",
    "#         cap.set(cv2.CAP_PROP_POS_MSEC, (sec_count * frame_rate))\n",
    "\n",
    "#         while True:\n",
    "#             ret, frame = cap.read()\n",
    "\n",
    "#             if ret:\n",
    "#                 try:\n",
    "#                     # Read eye coordinates from the corresponding txt file\n",
    "#                     eye_coords_filename = f'{input_filename[:-4]}.txt'\n",
    "#                     with open(eye_coords_filename, 'r') as coords_file:\n",
    "#                         lines = coords_file.readlines()\n",
    "#                         if sec_count >= len(lines):\n",
    "#                             break  # Stop processing frames if no more coordinates are available\n",
    "#                         eye_coords = list(map(int, lines[sec_count].split(',')[1:]))\n",
    "\n",
    "#                     # Use eye coordinates for face detection around the eyes\n",
    "#                     face_results = extract_face_using_eyes(frame, eye_coords)\n",
    "\n",
    "#                     # Draw rectangles around detected faces\n",
    "#                     if face_results is not None:\n",
    "#                         for box in face_results:\n",
    "#                             x, y, w, h = box\n",
    "#                             cv2.rectangle(frame, (int(x), int(y)), (int(x + w), int(y + h)), (0, 255, 0), 2)\n",
    "\n",
    "#                     # Save the frame with rectangles\n",
    "#                     write_path = output_path + f'{img_name}_{i}_{img_class}.png'\n",
    "#                     cv2.imwrite(write_path, frame)\n",
    "\n",
    "#                     i += 1\n",
    "#                     sec_count += 1\n",
    "\n",
    "#                 except Exception as e:\n",
    "#                     print(f\"Error processing frame: {e}\")\n",
    "\n",
    "#             else:\n",
    "#                 break\n",
    "\n",
    "#             delay = int(1000 / frame_rate)\n",
    "#             cv2.waitKey(delay)\n",
    "\n",
    "#         cap.release()\n",
    "\n",
    "#     return i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start(in_dir , out_dir, img_class, frame_rate=32, resize=256):\n",
    "    filescounter = os.listdir(in_dir)\n",
    "    # Count the number of files\n",
    "    num_files = len(filescounter)\n",
    "    print(num_files)\n",
    "    \n",
    "    # traverse whole directory\n",
    "    if not os.path.exists(out_dir):\n",
    "        os.makedirs(out_dir)\n",
    "    out_dir_real= os.path.join(out_dir, 'real/')\n",
    "    out_dir_attack= os.path.join(out_dir, 'attack/')\n",
    "    if not os.path.exists(out_dir_real):\n",
    "        os.makedirs(out_dir_real)\n",
    "    if not os.path.exists(out_dir_attack):\n",
    "        os.makedirs(out_dir_attack)\n",
    "    \n",
    "    real_dir_list = []\n",
    "    attack_dir_list = []\n",
    "    for root, dirs, files in os.walk(f'{in_dir}'):\n",
    "        # select file name\n",
    "        for file in files:\n",
    "            # check the extension of files\n",
    "            if file.endswith('.avi'):\n",
    "                # print whole path of files\n",
    "                base_name = os.path.splitext(file)[0]\n",
    "                if base_name[-1:] == '1':\n",
    "                    path = os.path.join(root, file)\n",
    "                    real_dir_list.append(path)\n",
    "                else:\n",
    "                    path = os.path.join(root, file)\n",
    "                    attack_dir_list.append(path)\n",
    "    count_real = extract_multiple_videos(real_dir_list,f'{out_dir_real}', resize=resize)\n",
    "    count_attack = extract_multiple_videos(attack_dir_list,f'{out_dir_attack}', resize=resize)\n",
    "    print(f'TOTAL FRAMES/IMAGES FORMED (REAL): {count_real}')\n",
    "    print(f'TOTAL FRAMES/IMAGES FORMED (ATTACK): {count_attack}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # START CAPTURING VIDEOS\n",
    "\n",
    "# def extract_attack_multiple_videos(input_filenames,output_path,img_class,frame_rate, resize):\n",
    "#     \"\"\"Extract video files into sequence of images.\n",
    "#        input_filenames is a list for video file names\"\"\"\n",
    "\n",
    "#     i = 0  # Counter of first video\n",
    "\n",
    "#     # Iterate file names:\n",
    "#     for input_filename in input_filenames:\n",
    "#         print(\"Processing video:\", input_filename)\n",
    "#         img_name = 'client'\n",
    "#         pattern = input_filename.split('/')\n",
    "#         for p in pattern:\n",
    "#             if 'client' in p:\n",
    "#                 f_name = p.split('_')\n",
    "#                 for name in f_name:\n",
    "#                     if name.find('client') != -1:\n",
    "#                         img_name = name\n",
    "        \n",
    "#         # print('the image will be named as:', img_name)\n",
    "        \n",
    "        \n",
    "#         sec_count = 0\n",
    "#         cap = cv2.VideoCapture(input_filename)\n",
    "#         cap.set(cv2.CAP_PROP_POS_MSEC,(sec_count*frame_rate))\n",
    "\n",
    "#         # Keep iterating break\n",
    "#         while True:\n",
    "#             ret, frame = cap.read()  # Read frame from first video\n",
    "#             if ret:\n",
    "#                 try:\n",
    "#                     cropped_faces = extract_face(frame)\n",
    "#                     cropped_faces = cv2.resize(cropped_faces,(resize,resize))\n",
    "#                     write_path = output_path + f'{img_name}_{i}_{img_class}.png'\n",
    "#                     cv2.imwrite(write_path, cropped_faces)  # Write frame to JPEG file (1.jpg, 2.jpg, ...)\n",
    "#                     i += 1 # Advance file counter\n",
    "#                     sec_count += 1\n",
    "#                 except:\n",
    "#                     pass\n",
    "#             else:\n",
    "#                 # Break the interal loop when res status is False.\n",
    "#                 break\n",
    "\n",
    "#             # cv2.waitKey(100) #Wait 100msec (for debugging)\n",
    "\n",
    "#         cap.release() #Release must be inside the outer loop\n",
    "#     return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def start_attack(in_dir , out_dir,img_class,frame_rate=32,resize=256):\n",
    "#     # traverse whole directory\n",
    "#     if not os.path.exists(out_dir):\n",
    "#         os.makedirs(out_dir)\n",
    "#     dir_list = []\n",
    "#     for root, dirs, files in os.walk(f'{in_dir}'):\n",
    "#         # select file name\n",
    "#         for file in files:\n",
    "#             # check the extension of files\n",
    "#             if file.endswith('.mov'):\n",
    "#                 # print whole path of files\n",
    "#                 path = os.path.join(root, file)\n",
    "#                 # print(path)\n",
    "#                 dir_list.append(path)\n",
    "#                 # extractImages(path,'./data/train/real',frame_rate=15000)\n",
    "#     count = extract_attack_multiple_videos(dir_list,f'{out_dir}',img_class,frame_rate=frame_rate, resize=resize)\n",
    "#     print(f'TOTAL FRAMES/IMAGES FORMED: {count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRANSFORMING TRAINING VIDEOS TO TRAINING IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vids_path = '/home/dinesh/Documents/Datasets/Face anti-spoofing datasets/OULU-NPU/Train_files'\n",
    "dev_vids_path = '/home/dinesh/Documents/Datasets/Face anti-spoofing datasets/OULU-NPU/Dev_files'\n",
    "test_vids_path = '/home/dinesh/Documents/Datasets/Face anti-spoofing datasets/OULU-NPU/Test_files'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs_path = '/home/dinesh/Documents/Datasets/Face anti-spoofing datasets/OULU-NPU-processed/train/'\n",
    "dev_imgs_path = '/home/dinesh/Documents/Datasets/Face anti-spoofing datasets/OULU-NPU-processed/dev/'\n",
    "test_imgs_path = '/home/dinesh/Documents/Datasets/Face anti-spoofing datasets/OULU-NPU-processed/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = {\"in_dir\": train_vids_path,\"out_dir\":train_imgs_path}\n",
    "dev_dir = {\"in_dir\":dev_vids_path, 'out_dir':dev_imgs_path}\n",
    "test_dir = {\"in_dir\":test_vids_path, 'out_dir':test_imgs_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3600\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f4ee68b0a7147889fed0f29a0583bda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Videos:   0%|          | 0/360 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mjpeg @ 0x55f42c8ae600] error dc\n",
      "[mjpeg @ 0x55f42c8ae600] error y=115 x=38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4_3_13_1.avi\n",
      "abnormal detections: 1\n",
      "5_1_06_1.avi\n",
      "no detections: 3\n",
      "Total abnormal detections count: 1\n",
      "Total No detections count: 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb852bfbb02542d4a2822b3ff98bf332",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Videos:   0%|          | 0/1440 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1_2_11_3.avi\n",
      "no detections: 138\n",
      "6_1_11_2.avi\n",
      "no detections: 11\n",
      "5_2_11_3.avi\n",
      "no detections: 8\n",
      "3_2_09_4.avi\n",
      "no detections: 27\n",
      "1_2_11_5.avi\n",
      "no detections: 151\n",
      "4_1_01_2.avi\n",
      "no detections: 101\n",
      "2_2_11_2.avi\n",
      "no detections: 15\n",
      "6_2_11_3.avi\n",
      "no detections: 20\n",
      "6_2_11_5.avi\n",
      "no detections: 35\n",
      "1_2_11_2.avi\n",
      "no detections: 114\n",
      "6_2_11_4.avi\n",
      "no detections: 14\n",
      "3_2_11_3.avi\n",
      "no detections: 5\n",
      "2_2_11_4.avi\n",
      "no detections: 39\n",
      "1_1_11_5.avi\n",
      "no detections: 1\n",
      "5_2_11_4.avi\n",
      "no detections: 55\n",
      "4_2_11_4.avi\n",
      "no detections: 25\n",
      "2_2_11_5.avi\n",
      "no detections: 73\n",
      "4_2_11_3.avi\n",
      "no detections: 1\n",
      "1_2_11_4.avi\n",
      "no detections: 111\n",
      "3_1_11_3.avi\n",
      "no detections: 2\n",
      "4_2_11_5.avi\n",
      "no detections: 120\n",
      "3_2_11_4.avi\n",
      "no detections: 5\n",
      "3_2_11_2.avi\n",
      "no detections: 50\n",
      "4_2_11_2.avi\n",
      "no detections: 88\n",
      "2_2_14_4.avi\n",
      "no detections: 1\n",
      "3_2_11_5.avi\n",
      "no detections: 151\n",
      "5_2_11_5.avi\n",
      "no detections: 89\n",
      "1_2_09_4.avi\n",
      "no detections: 14\n",
      "5_2_11_2.avi\n",
      "no detections: 33\n",
      "4_3_14_5.avi\n",
      "no detections: 1\n",
      "1_1_11_2.avi\n",
      "no detections: 1\n",
      "5_1_06_3.avi\n",
      "no detections: 1\n",
      "6_2_11_2.avi\n",
      "no detections: 65\n",
      "3_2_09_5.avi\n",
      "no detections: 119\n",
      "Total abnormal detections count: 0\n",
      "Total No detections count: 1684\n",
      "TOTAL FRAMES/IMAGES FORMED (REAL): 47621\n",
      "TOTAL FRAMES/IMAGES FORMED (ATTACK): 191276\n"
     ]
    }
   ],
   "source": [
    "start(train_dir['in_dir'],train_dir['out_dir'],img_class=\"train\",frame_rate=30,resize=256) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2700\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f516fc3233a4f9aa443cc80eb1fd69c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Videos:   0%|          | 0/270 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4_1_22_1.avi\n",
      "abnormal detections: 107\n",
      "no detections: 25\n",
      "6_1_22_1.avi\n",
      "abnormal detections: 50\n",
      "no detections: 40\n",
      "3_2_21_1.avi\n",
      "no detections: 3\n",
      "3_2_22_1.avi\n",
      "abnormal detections: 51\n",
      "no detections: 11\n",
      "2_1_22_1.avi\n",
      "abnormal detections: 15\n",
      "no detections: 33\n",
      "6_2_22_1.avi\n",
      "abnormal detections: 26\n",
      "no detections: 20\n",
      "1_1_22_1.avi\n",
      "abnormal detections: 77\n",
      "no detections: 56\n",
      "3_1_22_1.avi\n",
      "abnormal detections: 5\n",
      "no detections: 94\n",
      "2_2_22_1.avi\n",
      "abnormal detections: 19\n",
      "no detections: 1\n",
      "5_1_22_1.avi\n",
      "abnormal detections: 56\n",
      "no detections: 81\n",
      "5_2_22_1.avi\n",
      "abnormal detections: 48\n",
      "no detections: 73\n",
      "6_2_21_1.avi\n",
      "no detections: 1\n",
      "4_2_22_1.avi\n",
      "abnormal detections: 19\n",
      "no detections: 103\n",
      "1_2_22_1.avi\n",
      "abnormal detections: 73\n",
      "no detections: 49\n",
      "Total abnormal detections count: 546\n",
      "Total No detections count: 590\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c9995bf059d487b8a4aba64fd060e2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Videos:   0%|          | 0/1080 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3_2_22_2.avi\n",
      "abnormal detections: 1\n",
      "no detections: 116\n",
      "3_2_22_4.avi\n",
      "abnormal detections: 10\n",
      "no detections: 108\n",
      "1_1_22_2.avi\n",
      "abnormal detections: 21\n",
      "no detections: 130\n",
      "4_2_22_3.avi\n",
      "abnormal detections: 2\n",
      "no detections: 143\n",
      "3_1_28_4.avi\n",
      "no detections: 16\n",
      "2_2_22_3.avi\n",
      "abnormal detections: 15\n",
      "no detections: 81\n",
      "4_2_22_4.avi\n",
      "abnormal detections: 12\n",
      "no detections: 102\n",
      "6_1_22_4.avi\n",
      "abnormal detections: 2\n",
      "no detections: 76\n",
      "3_2_22_5.avi\n",
      "abnormal detections: 1\n",
      "no detections: 113\n",
      "2_2_22_2.avi\n",
      "abnormal detections: 29\n",
      "no detections: 62\n",
      "3_1_22_5.avi\n",
      "abnormal detections: 5\n",
      "no detections: 146\n",
      "4_1_22_4.avi\n",
      "abnormal detections: 89\n",
      "no detections: 55\n",
      "6_2_22_5.avi\n",
      "abnormal detections: 2\n",
      "no detections: 94\n",
      "3_2_22_3.avi\n",
      "abnormal detections: 3\n",
      "no detections: 89\n",
      "2_2_22_5.avi\n",
      "no detections: 94\n",
      "1_2_22_2.avi\n",
      "abnormal detections: 20\n",
      "no detections: 127\n",
      "1_1_22_5.avi\n",
      "abnormal detections: 6\n",
      "no detections: 145\n",
      "6_2_28_5.avi\n",
      "no detections: 1\n",
      "5_1_22_3.avi\n",
      "abnormal detections: 53\n",
      "no detections: 73\n",
      "6_1_22_2.avi\n",
      "abnormal detections: 35\n",
      "no detections: 85\n",
      "5_2_22_4.avi\n",
      "abnormal detections: 11\n",
      "no detections: 119\n",
      "2_1_22_3.avi\n",
      "abnormal detections: 41\n",
      "no detections: 55\n",
      "3_1_22_3.avi\n",
      "abnormal detections: 2\n",
      "no detections: 94\n",
      "2_1_22_2.avi\n",
      "abnormal detections: 1\n",
      "no detections: 95\n",
      "5_2_22_2.avi\n",
      "abnormal detections: 21\n",
      "no detections: 122\n",
      "1_1_22_3.avi\n",
      "abnormal detections: 1\n",
      "no detections: 150\n",
      "6_1_24_3.avi\n",
      "abnormal detections: 1\n",
      "2_2_22_4.avi\n",
      "abnormal detections: 10\n",
      "no detections: 102\n",
      "2_1_22_5.avi\n",
      "no detections: 30\n",
      "3_1_22_2.avi\n",
      "abnormal detections: 6\n",
      "no detections: 90\n",
      "4_1_22_5.avi\n",
      "abnormal detections: 3\n",
      "no detections: 135\n",
      "1_1_21_3.avi\n",
      "no detections: 2\n",
      "6_2_33_4.avi\n",
      "no detections: 1\n",
      "5_1_22_2.avi\n",
      "abnormal detections: 36\n",
      "no detections: 115\n",
      "5_2_22_3.avi\n",
      "abnormal detections: 23\n",
      "no detections: 127\n",
      "6_3_21_4.avi\n",
      "no detections: 1\n",
      "5_1_22_4.avi\n",
      "abnormal detections: 42\n",
      "no detections: 109\n",
      "5_2_22_5.avi\n",
      "abnormal detections: 1\n",
      "no detections: 149\n",
      "1_2_22_4.avi\n",
      "abnormal detections: 6\n",
      "no detections: 100\n",
      "5_1_22_5.avi\n",
      "abnormal detections: 1\n",
      "no detections: 145\n",
      "1_1_21_5.avi\n",
      "no detections: 3\n",
      "6_2_22_4.avi\n",
      "abnormal detections: 30\n",
      "no detections: 80\n",
      "4_2_22_5.avi\n",
      "abnormal detections: 2\n",
      "no detections: 134\n",
      "4_1_22_3.avi\n",
      "abnormal detections: 10\n",
      "no detections: 136\n",
      "6_2_22_2.avi\n",
      "abnormal detections: 36\n",
      "no detections: 85\n",
      "6_2_22_3.avi\n",
      "abnormal detections: 2\n",
      "no detections: 110\n",
      "3_1_22_4.avi\n",
      "abnormal detections: 40\n",
      "no detections: 80\n",
      "4_1_22_2.avi\n",
      "abnormal detections: 10\n",
      "no detections: 136\n",
      "1_1_22_4.avi\n",
      "abnormal detections: 14\n",
      "no detections: 136\n",
      "2_1_22_4.avi\n",
      "abnormal detections: 3\n",
      "no detections: 123\n",
      "1_2_22_5.avi\n",
      "abnormal detections: 6\n",
      "no detections: 142\n",
      "4_2_22_2.avi\n",
      "no detections: 124\n",
      "6_1_22_5.avi\n",
      "abnormal detections: 2\n",
      "no detections: 72\n",
      "1_2_22_3.avi\n",
      "abnormal detections: 52\n",
      "no detections: 99\n",
      "6_1_22_3.avi\n",
      "abnormal detections: 1\n",
      "no detections: 120\n",
      "Total abnormal detections count: 720\n",
      "Total No detections count: 5177\n",
      "TOTAL FRAMES/IMAGES FORMED (REAL): 34459\n",
      "TOTAL FRAMES/IMAGES FORMED (ATTACK): 138748\n"
     ]
    }
   ],
   "source": [
    "start(dev_dir['in_dir'],dev_dir['out_dir'],img_class=\"dev\",frame_rate=32,resize=256) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3600\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed54d8e71fd14f779509f4dc435ced7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Videos:   0%|          | 0/360 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5_3_44_1.avi\n",
      "no detections: 1\n",
      "3_2_40_1.avi\n",
      "no detections: 7\n",
      "6_2_40_1.avi\n",
      "no detections: 2\n",
      "1_1_40_1.avi\n",
      "no detections: 10\n",
      "4_2_44_1.avi\n",
      "abnormal detections: 44\n",
      "no detections: 90\n",
      "4_3_44_1.avi\n",
      "no detections: 9\n",
      "4_3_40_1.avi\n",
      "no detections: 30\n",
      "6_2_44_1.avi\n",
      "abnormal detections: 2\n",
      "no detections: 16\n",
      "4_1_40_1.avi\n",
      "no detections: 1\n",
      "3_1_40_1.avi\n",
      "no detections: 4\n",
      "1_1_44_1.avi\n",
      "no detections: 2\n",
      "2_2_44_1.avi\n",
      "abnormal detections: 16\n",
      "no detections: 24\n",
      "2_2_40_1.avi\n",
      "no detections: 1\n",
      "5_2_44_1.avi\n",
      "abnormal detections: 50\n",
      "no detections: 72\n",
      "1_2_44_1.avi\n",
      "abnormal detections: 11\n",
      "no detections: 83\n",
      "5_1_40_1.avi\n",
      "no detections: 20\n",
      "1_3_44_1.avi\n",
      "no detections: 1\n",
      "6_3_44_1.avi\n",
      "no detections: 15\n",
      "6_1_44_1.avi\n",
      "no detections: 1\n",
      "2_3_44_1.avi\n",
      "no detections: 8\n",
      "6_3_40_1.avi\n",
      "no detections: 1\n",
      "Total abnormal detections count: 123\n",
      "Total No detections count: 398\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a3108422e1a4d1c9bf3f21a6746a8ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Videos:   0%|          | 0/1440 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6_2_44_2.avi\n",
      "abnormal detections: 2\n",
      "no detections: 29\n",
      "3_2_44_5.avi\n",
      "no detections: 5\n",
      "5_3_40_3.avi\n",
      "no detections: 17\n",
      "5_1_40_2.avi\n",
      "no detections: 2\n",
      "6_2_40_4.avi\n",
      "no detections: 108\n",
      "5_3_40_4.avi\n",
      "no detections: 54\n",
      "2_1_54_2.avi\n",
      "no detections: 19\n",
      "5_1_40_4.avi\n",
      "no detections: 36\n",
      "1_2_54_2.avi\n",
      "no detections: 6\n",
      "3_1_40_2.avi\n",
      "no detections: 4\n",
      "4_2_44_3.avi\n",
      "no detections: 2\n",
      "2_2_44_2.avi\n",
      "abnormal detections: 1\n",
      "no detections: 27\n",
      "1_1_40_3.avi\n",
      "no detections: 2\n",
      "1_3_40_5.avi\n",
      "no detections: 139\n",
      "6_2_46_3.avi\n",
      "no detections: 1\n",
      "3_2_54_5.avi\n",
      "no detections: 24\n",
      "3_1_40_3.avi\n",
      "no detections: 2\n",
      "1_2_40_3.avi\n",
      "no detections: 14\n",
      "3_1_54_2.avi\n",
      "no detections: 1\n",
      "4_2_44_5.avi\n",
      "no detections: 9\n",
      "5_1_54_3.avi\n",
      "no detections: 108\n",
      "2_1_40_2.avi\n",
      "no detections: 6\n",
      "1_2_40_2.avi\n",
      "no detections: 2\n",
      "6_1_40_2.avi\n",
      "no detections: 17\n",
      "5_1_38_4.avi\n",
      "no detections: 1\n",
      "4_1_49_3.avi\n",
      "no detections: 31\n",
      "5_2_44_2.avi\n",
      "abnormal detections: 3\n",
      "no detections: 30\n",
      "6_2_44_5.avi\n",
      "abnormal detections: 1\n",
      "no detections: 85\n",
      "4_2_44_4.avi\n",
      "no detections: 8\n",
      "3_2_44_4.avi\n",
      "no detections: 12\n",
      "6_1_40_3.avi\n",
      "no detections: 1\n",
      "4_3_40_3.avi\n",
      "no detections: 16\n",
      "3_1_40_4.avi\n",
      "no detections: 41\n",
      "1_2_44_3.avi\n",
      "no detections: 10\n",
      "3_2_40_2.avi\n",
      "no detections: 1\n",
      "1_3_40_3.avi\n",
      "no detections: 5\n",
      "5_3_40_5.avi\n",
      "abnormal detections: 1\n",
      "no detections: 83\n",
      "6_1_40_4.avi\n",
      "no detections: 6\n",
      "4_2_40_5.avi\n",
      "no detections: 8\n",
      "4_2_40_2.avi\n",
      "no detections: 2\n",
      "2_3_40_3.avi\n",
      "no detections: 2\n",
      "6_3_40_4.avi\n",
      "abnormal detections: 1\n",
      "no detections: 43\n",
      "3_1_54_5.avi\n",
      "no detections: 149\n",
      "4_1_40_5.avi\n",
      "no detections: 19\n",
      "2_1_40_5.avi\n",
      "no detections: 7\n",
      "2_1_40_4.avi\n",
      "no detections: 22\n",
      "1_1_40_5.avi\n",
      "no detections: 43\n",
      "6_1_40_5.avi\n",
      "no detections: 21\n",
      "1_2_40_5.avi\n",
      "no detections: 49\n",
      "3_3_40_3.avi\n",
      "no detections: 29\n",
      "1_2_40_4.avi\n",
      "no detections: 5\n",
      "3_2_44_2.avi\n",
      "no detections: 19\n",
      "4_2_44_2.avi\n",
      "abnormal detections: 1\n",
      "no detections: 7\n",
      "3_2_44_3.avi\n",
      "no detections: 1\n",
      "1_2_44_5.avi\n",
      "no detections: 24\n",
      "1_3_44_2.avi\n",
      "no detections: 1\n",
      "2_2_44_4.avi\n",
      "abnormal detections: 1\n",
      "no detections: 9\n",
      "4_3_40_5.avi\n",
      "no detections: 67\n",
      "6_2_40_3.avi\n",
      "no detections: 11\n",
      "6_1_49_3.avi\n",
      "no detections: 1\n",
      "1_1_40_2.avi\n",
      "no detections: 25\n",
      "1_2_44_2.avi\n",
      "no detections: 4\n",
      "3_1_54_4.avi\n",
      "no detections: 54\n",
      "5_1_49_3.avi\n",
      "no detections: 7\n",
      "6_3_40_5.avi\n",
      "abnormal detections: 2\n",
      "no detections: 48\n",
      "3_2_40_5.avi\n",
      "no detections: 2\n",
      "1_1_54_4.avi\n",
      "no detections: 65\n",
      "1_3_40_2.avi\n",
      "no detections: 12\n",
      "6_2_44_4.avi\n",
      "abnormal detections: 1\n",
      "no detections: 76\n",
      "1_2_44_4.avi\n",
      "no detections: 22\n",
      "2_2_54_5.avi\n",
      "no detections: 1\n",
      "3_1_40_5.avi\n",
      "no detections: 38\n",
      "2_2_44_5.avi\n",
      "no detections: 7\n",
      "6_2_40_2.avi\n",
      "no detections: 60\n",
      "3_3_40_2.avi\n",
      "no detections: 1\n",
      "4_1_40_2.avi\n",
      "no detections: 9\n",
      "2_1_54_5.avi\n",
      "no detections: 11\n",
      "2_3_40_2.avi\n",
      "no detections: 1\n",
      "3_3_40_4.avi\n",
      "no detections: 10\n",
      "6_2_40_5.avi\n",
      "no detections: 86\n",
      "4_1_40_4.avi\n",
      "no detections: 51\n",
      "6_2_44_3.avi\n",
      "abnormal detections: 1\n",
      "no detections: 18\n",
      "1_1_49_5.avi\n",
      "no detections: 1\n",
      "5_2_44_5.avi\n",
      "no detections: 16\n",
      "2_2_40_5.avi\n",
      "no detections: 6\n",
      "1_1_54_5.avi\n",
      "no detections: 3\n",
      "1_3_40_4.avi\n",
      "no detections: 16\n",
      "5_3_40_2.avi\n",
      "no detections: 9\n",
      "1_1_40_4.avi\n",
      "no detections: 69\n",
      "5_2_44_3.avi\n",
      "no detections: 10\n",
      "2_2_44_3.avi\n",
      "no detections: 4\n",
      "1_1_54_3.avi\n",
      "no detections: 122\n",
      "6_3_40_3.avi\n",
      "abnormal detections: 1\n",
      "no detections: 18\n",
      "5_2_44_4.avi\n",
      "no detections: 11\n",
      "6_3_40_2.avi\n",
      "no detections: 2\n",
      "5_1_40_5.avi\n",
      "no detections: 58\n",
      "3_3_40_5.avi\n",
      "no detections: 13\n",
      "4_3_40_4.avi\n",
      "no detections: 68\n",
      "2_1_54_4.avi\n",
      "no detections: 6\n",
      "2_3_40_4.avi\n",
      "no detections: 48\n",
      "2_3_40_5.avi\n",
      "no detections: 51\n",
      "Total abnormal detections count: 16\n",
      "Total No detections count: 2642\n",
      "TOTAL FRAMES/IMAGES FORMED (REAL): 47045\n",
      "TOTAL FRAMES/IMAGES FORMED (ATTACK): 190856\n"
     ]
    }
   ],
   "source": [
    "start(test_dir['in_dir'],test_dir['out_dir'],img_class=\"test\",frame_rate=32,resize=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRANSFORMING TEST VIDEOS TO TESTING IMAGES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_real_vids_path = 'D:/BTP/dataset/Replay-Attack/test/real/'\n",
    "test_spoof_fixed_vids_path = 'D:/BTP/dataset/Replay-Attack/test/attack/fixed/'\n",
    "test_spoof_hand_vids_path = 'D:/BTP/dataset/Replay-Attack/test/attack/hand/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_real_imgs_path = './data/Replay-Attack-processed/test/real/'\n",
    "test_spoof_fixed_imgs_path = './data/Replay-Attack-processed/test/spoof/fixed/'\n",
    "test_spoof_hand_imgs_path = './data/Replay-Attack-processed/test/spoof/hand/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir_real = {\"in_dir\": test_real_vids_path,\"out_dir\":test_real_imgs_path}\n",
    "test_dir_attack_fixed = {\"in_dir\":test_spoof_fixed_vids_path, 'out_dir':test_spoof_fixed_imgs_path}\n",
    "test_dir_attack_hand = {\"in_dir\":test_spoof_hand_vids_path, 'out_dir':test_spoof_hand_imgs_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL FRAMES/IMAGES FORMED: 29229\n"
     ]
    }
   ],
   "source": [
    "start(test_dir_real['in_dir'],test_dir_real['out_dir'],img_class=\"real\",frame_rate=2000,resize=256) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL FRAMES/IMAGES FORMED: 46700\n"
     ]
    }
   ],
   "source": [
    "start(test_dir_attack_fixed['in_dir'],test_dir_attack_fixed['out_dir'],img_class=\"attack_fixed\",frame_rate=500,resize=256) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL FRAMES/IMAGES FORMED: 44487\n"
     ]
    }
   ],
   "source": [
    "start(test_dir_attack_hand['in_dir'],test_dir_attack_hand['out_dir'],img_class=\"attack_hand\",frame_rate=500,resize=256) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data saved to train_data.csv\n",
      "Test data saved to test_data.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import csv\n",
    "\n",
    "# Define the paths to your train and test folders\n",
    "train_folder = './data/Replay-Attack-processed/train/'\n",
    "test_folder = './data/Replay-Attack-processed/test/'\n",
    "\n",
    "# Function to label and shuffle data in a folder\n",
    "def process_folder(folder_path, label):\n",
    "    image_paths = []\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.png'):\n",
    "                image_path = os.path.join(root, file)\n",
    "                image_paths.append((image_path, label))\n",
    "    \n",
    "    # Shuffle the image paths\n",
    "    random.shuffle(image_paths)\n",
    "    \n",
    "    return image_paths\n",
    "\n",
    "# Process the train and test folders\n",
    "train_real_paths = process_folder(os.path.join(train_folder, 'real'), 1)\n",
    "test_real_paths = process_folder(os.path.join(test_folder, 'real'), 1)\n",
    "\n",
    "# Include images from the \"hand\" and \"fixed\" subfolders within the \"spoof\" folder\n",
    "train_fake_paths = process_folder(os.path.join(train_folder, 'spoof/hand'), 0)\n",
    "train_fake_paths += process_folder(os.path.join(train_folder, 'spoof/fixed'), 0)\n",
    "\n",
    "test_fake_paths = process_folder(os.path.join(test_folder, 'spoof/hand'), 0)\n",
    "test_fake_paths += process_folder(os.path.join(test_folder, 'spoof/fixed'), 0)\n",
    "\n",
    "# Combine real and fake paths\n",
    "train_data = train_real_paths + train_fake_paths\n",
    "test_data = test_real_paths + test_fake_paths\n",
    "\n",
    "# Shuffle the combined data\n",
    "random.shuffle(train_data)\n",
    "random.shuffle(test_data)\n",
    "\n",
    "# Define CSV filenames\n",
    "train_csv_filename = 'train_data.csv'\n",
    "test_csv_filename = 'test_data.csv'\n",
    "\n",
    "# Write data to CSV files\n",
    "def write_to_csv(filename, data):\n",
    "    with open(filename, 'w', newline='') as csvfile:\n",
    "        csv_writer = csv.writer(csvfile)\n",
    "        csv_writer.writerow(['name', 'label'])\n",
    "        csv_writer.writerows(data)\n",
    "\n",
    "write_to_csv(train_csv_filename, train_data)\n",
    "write_to_csv(test_csv_filename, test_data)\n",
    "\n",
    "print(f\"Train data saved to {train_csv_filename}\")\n",
    "print(f\"Test data saved to {test_csv_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CHANGE DIRECTORY STRUCTURE BY PLACING IMAGES PERSON WISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_wise_dataset_train_path = './data/Reply-Attack-processed/train/images/' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dir_list(path):\n",
    "    dir_list = []\n",
    "    for root, dirs, files in os.walk(f'{path}'):\n",
    "        # select file name\n",
    "        for file in files:\n",
    "            # check the extension of files\n",
    "            if file.endswith('.png'):\n",
    "                # print whole path of files\n",
    "                path = os.path.join(root, file)\n",
    "                # print(path)\n",
    "                dir_list.append(path)\n",
    "    return dir_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22490\n",
      "35438\n",
      "33707\n"
     ]
    }
   ],
   "source": [
    "img_path_list_train_real = get_dir_list(train_real_imgs_path)\n",
    "img_path_list_train_spoof_fixed = get_dir_list(train_spoof_fixed_imgs_path)\n",
    "img_path_list_train_spoof_hand = get_dir_list(train_spoof_hand_imgs_path)\n",
    "print(len(img_path_list_train_real)) # ./replay-images/train/real/\n",
    "print(len(img_path_list_train_spoof_fixed)) # ./replay-images/train/spoof/fixed\n",
    "print(len(img_path_list_train_spoof_hand)) # ./replay-images/train/spoof/hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./data/Reply-Attack-processed/train/real/client001_0_real.png'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_path_list_train_real[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_client_objects(path_list):\n",
    "    clients = {}\n",
    "    for file in path_list:\n",
    "        path_parts = file.split('/')\n",
    "        for part in path_parts:\n",
    "            if 'client' in part:\n",
    "                file_name_split = part.split('_')\n",
    "                client_key = file_name_split[0]\n",
    "                if client_key in clients.keys():\n",
    "                    clients[client_key].append(file)\n",
    "                else:\n",
    "                    clients[client_key] = [file]\n",
    "    return clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_client_objects =  get_client_objects(img_path_list_train_real)\n",
    "spoof_fixed_client_objects = get_client_objects(img_path_list_train_spoof_fixed)\n",
    "spoof_hand_client_objects = get_client_objects(img_path_list_train_spoof_hand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['client001', 'client002', 'client004', 'client006', 'client007', 'client008', 'client012', 'client016', 'client018', 'client025', 'client027', 'client103', 'client105', 'client108', 'client110']\n",
      "['client001', 'client002', 'client004', 'client006', 'client007', 'client008', 'client012', 'client016', 'client018', 'client025', 'client027', 'client103', 'client105', 'client108', 'client110']\n",
      "['client001', 'client002', 'client004', 'client006', 'client007', 'client008', 'client012', 'client016', 'client018', 'client025', 'client027', 'client103', 'client105', 'client108', 'client110']\n"
     ]
    }
   ],
   "source": [
    "print(sorted(real_client_objects.keys()))\n",
    "print(sorted(spoof_fixed_client_objects.keys()))\n",
    "print(sorted(spoof_hand_client_objects.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_wise_dir_list = get_dir_list(person_wise_dataset_train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "person_wise_dir_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " DataGeneration.ipynb                              \u001b[0m\u001b[01;34mreplay-dummy-person-wise\u001b[0m/\r\n",
      " \u001b[01;34mdataset\u001b[0m/                                          \u001b[01;34mreplay-images\u001b[0m/\r\n",
      " haarcascade_frontalface_default.xml               \u001b[01;35mtest_img.png\u001b[0m\r\n",
      "'PIxel Wise Supervision - Siamese-Network.ipynb'\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREATE list.txt AND APPEND FORMATED PATHS OF IMAGES TO IT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/Reply-Attack-processed/train/list.txt', 'w') as f:\n",
    "    for path in person_wise_dir_list:\n",
    "        if '/data/Reply-Attack-processed/train/images/' in path:\n",
    "            s = path.split('/data/Reply-Attack-processed/train/images/')\n",
    "            p = s[1]\n",
    "            f.write(\"%s\\n\" % p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: './data/Reply-Attack-processed/train/images/client001'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\BTP\\maincode\\replay-attack-processing.ipynb Cell 41\u001b[0m in \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/BTP/maincode/replay-attack-processing.ipynb#X45sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     shutil\u001b[39m.\u001b[39mrmtree(person_wise_dataset_train_path\u001b[39m+\u001b[39mclient_key)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/BTP/maincode/replay-attack-processing.ipynb#X45sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m single_client_path \u001b[39m=\u001b[39m person_wise_dataset_train_path\u001b[39m+\u001b[39mclient_key\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/BTP/maincode/replay-attack-processing.ipynb#X45sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m os\u001b[39m.\u001b[39;49mmkdir(single_client_path)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/BTP/maincode/replay-attack-processing.ipynb#X45sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m single_client_path_real \u001b[39m=\u001b[39m single_client_path \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/real\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/BTP/maincode/replay-attack-processing.ipynb#X45sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m single_client_path_spoof \u001b[39m=\u001b[39m single_client_path \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/spoof\u001b[39m\u001b[39m'\u001b[39m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: './data/Reply-Attack-processed/train/images/client001'"
     ]
    }
   ],
   "source": [
    "for client_key in sorted(real_client_objects.keys()):\n",
    "    if os.path.isdir(person_wise_dataset_train_path+client_key):\n",
    "        shutil.rmtree(person_wise_dataset_train_path+client_key)\n",
    "    single_client_path = person_wise_dataset_train_path+client_key\n",
    "    os.mkdir(single_client_path)\n",
    "    \n",
    "    single_client_path_real = single_client_path + '/real'\n",
    "    single_client_path_spoof = single_client_path + '/spoof'\n",
    "    os.mkdir(single_client_path_real)\n",
    "    os.mkdir(single_client_path_spoof)\n",
    "    for raw_client_image_path in real_client_objects[client_key]:\n",
    "        shutil.copy2(raw_client_image_path,single_client_path_real)\n",
    "    for raw_client_image_path in spoof_fixed_client_objects[client_key]:\n",
    "        shutil.copy2(raw_client_image_path,single_client_path_spoof)\n",
    "    for raw_client_image_path in spoof_hand_client_objects[client_key]:\n",
    "        shutil.copy2(raw_client_image_path,single_client_path_spoof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchKernel",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
