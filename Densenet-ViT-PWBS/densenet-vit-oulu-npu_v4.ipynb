{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torchvision.models import densenet121\n",
    "import torchvision.models as models\n",
    "# from vit_pytorch import ViT\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH']='true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dinesh/miniforge3/envs/pytorch/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/dinesh/miniforge3/envs/pytorch/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Using cache found in /home/dinesh/.cache/torch/hub/facebookresearch_deit_main\n",
      "  0%|                                       | 6/7466 [01:09<23:47:07, 11.48s/it]"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define your dataset class\n",
    "class SpoofingDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # img_name = os.path.join(self.root_dir, self.data.iloc[idx, 0][60:])\n",
    "        img_name = self.data.iloc[idx, 0]\n",
    "        image = Image.open(img_name).convert(\"RGB\")\n",
    "        label = self.data.iloc[idx, 1]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "# Define data augmentation transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(224, padding=10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Load your dataset\n",
    "root_dir = ''\n",
    "train_dataset = SpoofingDataset(csv_file=os.path.join('./OULU-NPU-csv', 'train_data.csv'), root_dir=root_dir, transform=transform)\n",
    "val_dataset = SpoofingDataset(csv_file=os.path.join('./OULU-NPU-csv/', 'dev_data.csv'), root_dir=root_dir, transform=transform)\n",
    "test_dataset = SpoofingDataset(csv_file=os.path.join('./OULU-NPU-csv', 'test_data.csv'), root_dir=root_dir, transform=transform)\n",
    "\n",
    "# Define data loaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Define the ViT model with DenseNet backbone\n",
    "class ViT_DenseNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ViT_DenseNet, self).__init__()\n",
    "        # Load the pre-trained DenseNet\n",
    "        self.densenet = models.densenet121(pretrained=True)\n",
    "        \n",
    "        # Remove the classification layer of DenseNet\n",
    "        self.densenet = nn.Sequential(*list(self.densenet.children())[:-1])\n",
    "        self.reduce_channels = nn.Conv2d(in_channels=1024, out_channels=3, kernel_size=1)\n",
    "        # Create the ViT model\n",
    "        self.vit = torch.hub.load('facebookresearch/deit:main', 'deit_base_patch16_224', pretrained=True)\n",
    "        # Separate branch for binary supervision loss calculation\n",
    "        self.supervision_branch = nn.Conv2d(1024, 1, kernel_size=1)\n",
    "        \n",
    "        self.fc = nn.Linear(1000, num_classes)  # Output layer for binary classification\n",
    "\n",
    "    def forward(self, x):\n",
    "        densenet_output = self.densenet(x)\n",
    "\n",
    "        supervision_output = self.supervision_branch(densenet_output)  # For supervision loss\n",
    "        # print('supervision_output', supervision_output.shape)\n",
    "\n",
    "        resized_output = F.interpolate(densenet_output, scale_factor=32, mode='bilinear', align_corners=False)\n",
    "        # print('resized_output', resized_output.shape)\n",
    "        reduced_output = self.reduce_channels(resized_output)\n",
    "        # print('reduced_output', reduced_output.shape)\n",
    "        \n",
    "        vit_output = self.vit(reduced_output)  # For classification\n",
    "        # print('vit_output', vit_output.shape)\n",
    "\n",
    "        final_output = self.fc(vit_output)\n",
    "        # print('final_output', final_output.shape)\n",
    "        \n",
    "        return supervision_output, final_output\n",
    "\n",
    "# Define the model, loss functions, and optimizer\n",
    "model = ViT_DenseNet(num_classes=1)  # 1 output for binary classification\n",
    "# mse_criterion = nn.MSELoss()  # Mean Squared Error loss\n",
    "bce_criterion = nn.BCEWithLogitsLoss()  # Binary Cross-Entropy loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 5\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "# if torch.cuda.is_available():\n",
    "#     if torch.cuda.device_count()>1:\n",
    "#         model=torch.nn.DataParallel(model)\n",
    "#     model.to(device)\n",
    "# else:\n",
    "#     raise NotImplementedError('This code unable to use GPU')\n",
    "model.to(device)\n",
    "\n",
    "logging.basicConfig(filename='training_log.txt', level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_losses_bcep = []\n",
    "    train_losses_bce = []\n",
    "    total_training_loss = []\n",
    "    for images, labels in tqdm(train_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass through the model\n",
    "        supervision_output, final_output = model(images)\n",
    "        \n",
    "        # Calculate the binary supervision loss using MSE\n",
    "        batch_size = labels.size(0)\n",
    "        # Repeat labels tensor over the dimensions of supervision_output\n",
    "        supervision_labels = labels.view(batch_size, 1, 1, 1).repeat(1, 1, 7, 7)\n",
    "        \n",
    "        supervision_loss = bce_criterion(supervision_output.view(-1), supervision_labels.view(-1).float())\n",
    "        \n",
    "        # Calculate the binary cross-entropy loss using BCE\n",
    "\n",
    "        # Create the target tensor with the same shape as final_output\n",
    "        # Reshape labels to have shape [batch_size, 1]\n",
    "        labels = labels.unsqueeze(1)\n",
    "        \n",
    "        # Create final_labels tensor\n",
    "        final_labels = torch.ones_like(final_output) * labels  # Broadcasting to match final_output shape\n",
    "\n",
    "        cross_entropy_loss = bce_criterion(final_output.view(-1), final_labels.view(-1).float())\n",
    "        \n",
    "        # Calculate the total loss\n",
    "        theta = 0.3  # Adjust as needed\n",
    "        total_loss = (1 - theta) * cross_entropy_loss + theta * supervision_loss\n",
    "        \n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        train_losses_bcep.append(supervision_loss.item())\n",
    "        train_losses_bce.append(cross_entropy_loss.item())\n",
    "        total_training_loss.append(total_loss.item())\n",
    "    \n",
    "    model.eval()\n",
    "    val_losses_bcep = []\n",
    "    val_losses_bce = []\n",
    "    total_val_loss = []\n",
    "    val_predictions = []\n",
    "    val_true_labels = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(val_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            supervision_output, final_output = model(images)\n",
    "            batch_size = labels.size(0)\n",
    "            # Repeat labels tensor over the dimensions of supervision_output\n",
    "            supervision_labels = labels.view(batch_size, 1, 1, 1).repeat(1, 1, 7, 7)\n",
    "            # Calculate the MSE loss for validation\n",
    "            supervision_loss = bce_criterion(supervision_output.view(-1), supervision_labels.view(-1).float())\n",
    "            val_losses_bcep.append(supervision_loss.item())\n",
    "            \n",
    "            # Calculate the BCE loss for validation\n",
    "            labels = labels.unsqueeze(1)\n",
    "\n",
    "            # Create final_labels tensor\n",
    "            final_labels = torch.ones_like(final_output) * labels  # Broadcasting to match final_output shape\n",
    "\n",
    "            cross_entropy_loss = bce_criterion(final_output.view(-1), final_labels.view(-1).float())\n",
    "            val_losses_bce.append(cross_entropy_loss.item())\n",
    "\n",
    "            theta = 0.3  # Adjust as needed\n",
    "            total_valid_loss = (1 - theta) * cross_entropy_loss + theta * supervision_loss\n",
    "            total_val_loss.append(total_valid_loss.item())\n",
    "\n",
    "            val_predictions.extend(torch.sigmoid(final_output).cpu().numpy())\n",
    "            val_true_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # Calculate validation accuracy\n",
    "    val_predictions = [1 if x >= 0.5 else 0 for x in val_predictions]\n",
    "    val_accuracy = accuracy_score(val_true_labels, val_predictions)\n",
    "\n",
    "    # Save the model checkpoint\n",
    "    checkpoint_path = f'densenetViT_OULU_NPU_checkpoint_v4_epoch_{epoch+1}.pt'\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'train_losses_bcep': train_losses_bcep,\n",
    "        'train_losses_bce': train_losses_bce,\n",
    "        'total_training_loss': total_training_loss,\n",
    "        'val_losses_bcep': val_losses_bcep,\n",
    "        'val_losses_bce': val_losses_bce,\n",
    "        'total_val_loss': total_val_loss,\n",
    "        'val_predictions': val_predictions,\n",
    "        'val_true_labels': val_true_labels,\n",
    "        'val_accuracy': val_accuracy\n",
    "    }, checkpoint_path)\n",
    "    logging.info(f\"Model checkpoint saved at: {checkpoint_path}\") \n",
    "    \n",
    "    # Log the values\n",
    "    logging.info(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
    "    logging.info(f\"Training BCE supervision Loss: {sum(train_losses_bcep) / len(train_losses_bcep):.4f}\")\n",
    "    logging.info(f\"Training BCE classification Loss: {sum(train_losses_bce) / len(train_losses_bce):.4f}\")\n",
    "    logging.info(f\"Training Total Loss: {sum(total_training_loss) / len(total_training_loss):.4f}\")\n",
    "    logging.info(f\"Validation BCE supervision Loss: {sum(val_losses_bcep) / len(val_losses_bcep):.4f}\")\n",
    "    logging.info(f\"Validation BCE classification Loss: {sum(val_losses_bce) / len(val_losses_bce):.4f}\")\n",
    "    logging.info(f\"Validation Total Loss: {sum(total_val_loss) / len(total_val_loss):.4f}\")\n",
    "    logging.info(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
    "    print(f\"Training BCE supervision Loss: {sum(train_losses_bcep) / len(train_losses_bcep):.4f}\")\n",
    "    print(f\"Training BCE classification Loss: {sum(train_losses_bce) / len(train_losses_bce):.4f}\")\n",
    "    print(f\"Validation BCE supervision Loss: {sum(val_losses_bcep) / len(val_losses_bcep):.4f}\")\n",
    "    print(f\"Validation BCE classification Loss: {sum(val_losses_bce) / len(val_losses_bce):.4f}\")\n",
    "    print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "    \n",
    "\n",
    "test_losses_bcep = []\n",
    "test_losses_bce = []\n",
    "total_test_loss = []\n",
    "test_predictions = []\n",
    "test_true_labels = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(test_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        supervision_output, final_output = model(images)\n",
    "        batch_size = labels.size(0)\n",
    "        # Repeat labels tensor over the dimensions of supervision_output\n",
    "        supervision_labels = labels.view(batch_size, 1, 1, 1).repeat(1, 1, 7, 7)\n",
    "        # Calculate the MSE loss for validation\n",
    "        supervision_loss = bce_criterion(supervision_output.view(-1), supervision_labels.view(-1).float())\n",
    "        test_losses_bcep.append(supervision_loss.item())\n",
    "\n",
    "        # Calculate the BCE loss for validation\n",
    "        labels = labels.unsqueeze(1)\n",
    "\n",
    "        # Create final_labels tensor\n",
    "        final_labels = torch.ones_like(final_output) * labels  # Broadcasting to match final_output shape\n",
    "\n",
    "        cross_entropy_loss = bce_criterion(final_output.view(-1), final_labels.view(-1).float())\n",
    "        test_losses_bce.append(cross_entropy_loss.item())\n",
    "\n",
    "        theta = 0.3  # Adjust as needed\n",
    "        total_testing_loss = (1 - theta) * cross_entropy_loss + theta * supervision_loss\n",
    "        total_test_loss.append(total_testing_loss.item())\n",
    "\n",
    "        test_predictions.extend(torch.sigmoid(final_output).cpu().numpy())\n",
    "        test_true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Calculate validation accuracy\n",
    "test_predictions = [1 if x >= 0.5 else 0 for x in test_predictions]\n",
    "test_accuracy = accuracy_score(test_true_labels, test_predictions)\n",
    "logging.info(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import FileLink\n",
    "# FileLink(r'/kaggle/working/densenetViT_OULU_NPU_checkpoint_epoch_1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-09-23T12:42:23.598860Z",
     "iopub.status.idle": "2023-09-23T12:42:23.601298Z",
     "shell.execute_reply": "2023-09-23T12:42:23.601127Z",
     "shell.execute_reply.started": "2023-09-23T12:42:23.601108Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save the model\n",
    "saved_model_path = 'densenet_vit_OULU_NPU.pth'\n",
    "torch.save(model.state_dict(), saved_model_path)\n",
    "print(f\"Model saved at {saved_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file = './exp3_training_log.txt'\n",
    "\n",
    "epochs = []\n",
    "train_bcep_losses = []\n",
    "train_bce_losses = []\n",
    "train_total_losses = []\n",
    "val_bcep_losses = []\n",
    "val_bce_losses = []\n",
    "val_total_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "with open(log_file, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        if 'Epoch' in line:\n",
    "            epochs.append(int(line.split('/')[0].split('[')[1]))\n",
    "        elif 'Training BCE supervision Loss' in line:\n",
    "            train_bcep_losses.append(float(line.split(': ')[1]))\n",
    "        elif 'Training BCE classification Loss' in line:\n",
    "            train_bce_losses.append(float(line.split(': ')[1]))\n",
    "        # elif 'Training Total Loss' in line:\n",
    "        #     train_total_losses.append(float(line.split(': ')[1]))\n",
    "        elif 'Validation BCE supervision Loss' in line:\n",
    "            val_bcep_losses.append(float(line.split(': ')[1]))\n",
    "        elif 'Validation BCE classification Loss' in line:\n",
    "            val_bce_losses.append(float(line.split(': ')[1]))\n",
    "        # elif 'Validation Total Loss' in line:\n",
    "        #     val_total_losses.append(float(line.split(': ')[1]))\n",
    "        elif 'Validation Accuracy' in line:\n",
    "            val_accuracies.append(float(line.split(': ')[1]))\n",
    "\n",
    "# Now you have the extracted information, you can use it to create plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot total loss\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# plt.subplot(2, 2, 1)\n",
    "# plt.plot(epochs, train_total_losses, label='Training')\n",
    "# plt.plot(epochs, val_total_losses, label='Validation')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Total Loss')\n",
    "# plt.title('Total Loss Over Epochs')\n",
    "# plt.legend()\n",
    "\n",
    "# Plot MSE loss\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(epochs, train_bcep_losses, label='Training')\n",
    "plt.plot(epochs, val_bcep_losses, label='Validation')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('BCE supervision Loss')\n",
    "plt.title('BCE supervision Loss Over Epochs')\n",
    "plt.legend()\n",
    "\n",
    "# Plot BCE loss\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(epochs, train_bce_losses, label='Training')\n",
    "plt.plot(epochs, val_bce_losses, label='Validation')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('BCE classification Loss')\n",
    "plt.title('BCE classification Loss Over Epochs')\n",
    "plt.legend()\n",
    "\n",
    "# Plot accuracy\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.plot(epochs, val_accuracies, label='Validation')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy Over Epochs')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchKernel",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
