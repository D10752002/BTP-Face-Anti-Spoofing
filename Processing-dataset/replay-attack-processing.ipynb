{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing replay-attack into image frames for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "import random\n",
    "import string\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "# from imutils import face_utils\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('./haarcascade_frontalface_default.xml')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_face(img):\n",
    "    # Convert to grayscale \n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  \n",
    "  \n",
    "    # Detect the faces  \n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 4)  \n",
    "    \n",
    "    # Draw rectangle around the faces and crop the faces\n",
    "    for (x, y, w, h) in faces:\n",
    "        faces = img[y:y + h, x:x + w]\n",
    "        \n",
    "    return faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./test_img.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  0,  12,   7],\n",
       "        [ 44,  54,  51],\n",
       "        [ 33,  46,  42],\n",
       "        ...,\n",
       "        [182, 192, 185],\n",
       "        [185, 196, 190],\n",
       "        [190, 204, 198]],\n",
       "\n",
       "       [[  0,  17,  12],\n",
       "        [ 66,  81,  77],\n",
       "        [ 65,  80,  74],\n",
       "        ...,\n",
       "        [178, 190, 185],\n",
       "        [182, 197, 194],\n",
       "        [191, 208, 205]],\n",
       "\n",
       "       [[ 47,  63,  58],\n",
       "        [ 36,  54,  49],\n",
       "        [  0,  21,  11],\n",
       "        ...,\n",
       "        [184, 199, 196],\n",
       "        [182, 201, 199],\n",
       "        [184, 203, 202]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 14,  18,  24],\n",
       "        [ 14,  19,  26],\n",
       "        [  9,  18,  27],\n",
       "        ...,\n",
       "        [185, 201, 210],\n",
       "        [178, 193, 201],\n",
       "        [167, 181, 188]],\n",
       "\n",
       "       [[ 14,  18,  25],\n",
       "        [ 12,  18,  25],\n",
       "        [  4,  14,  24],\n",
       "        ...,\n",
       "        [188, 203, 210],\n",
       "        [177, 191, 196],\n",
       "        [164, 178, 180]],\n",
       "\n",
       "       [[ 11,  14,  25],\n",
       "        [ 19,  24,  34],\n",
       "        [ 14,  21,  33],\n",
       "        ...,\n",
       "        [188, 201, 206],\n",
       "        [183, 194, 197],\n",
       "        [178, 188, 190]]], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_face(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_face_and_save(image_path, output_path):\n",
    "    # Load the image\n",
    "    img = cv2.imread(image_path)\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "  \n",
    "    # Detect the faces\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 4)\n",
    "    \n",
    "    # Draw rectangle around the faces and save the image\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)  # Draw a green rectangle around the face\n",
    "        \n",
    "    # Save the image with rectangles\n",
    "    cv2.imwrite(output_path, img)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image_path = './test_img.png'\n",
    "output_image_path = 'test_img_output_face_bound.png'\n",
    "output_image = extract_face_and_save(input_image_path, output_image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# START CAPTURING VIDEOS\n",
    "\n",
    "def extract_multiple_videos(intput_filenames,pathOut,img_class,frame_rate, resize):\n",
    "    \"\"\"Extract video files into sequence of images.\n",
    "       Intput_filenames is a list for video file names\"\"\"\n",
    "\n",
    "    i = 0  # Counter of first video\n",
    "\n",
    "    # Iterate file names:\n",
    "    for intput_filename in intput_filenames:\n",
    "        img_name = 'client'\n",
    "        pattern = intput_filename.split('/')\n",
    "        for p in pattern:\n",
    "            if 'client' in p:\n",
    "                f_name = p.split('_')\n",
    "                for name in f_name:\n",
    "                    if name.find('client') != -1:\n",
    "                        img_name = name\n",
    "        \n",
    "        # print('the image will be named as:', img_name)\n",
    "        \n",
    "        \n",
    "        sec_count = 0\n",
    "        cap = cv2.VideoCapture(intput_filename)\n",
    "        cap.set(cv2.CAP_PROP_POS_MSEC,(sec_count*frame_rate))\n",
    "\n",
    "        # Keep iterating break\n",
    "        while True:\n",
    "            ret, frame = cap.read()  # Read frame from first video\n",
    "\n",
    "            if ret:\n",
    "                try:\n",
    "                    cropped_faces = extract_face(frame)\n",
    "                    cropped_faces = cv2.resize(cropped_faces,(resize,resize))\n",
    "                    write_path = pathOut + f'{img_name}_{i}_{img_class}.png'\n",
    "                    cv2.imwrite(write_path, cropped_faces)  # Write frame to JPEG file (1.jpg, 2.jpg, ...)\n",
    "                    i += 1 # Advance file counter\n",
    "                    sec_count += 1\n",
    "                except:\n",
    "                    pass\n",
    "            else:\n",
    "                # Break the interal loop when res status is False.\n",
    "                break\n",
    "\n",
    "            # cv2.waitKey(100) #Wait 100msec (for debugging)\n",
    "\n",
    "        cap.release() #Release must be inside the outer loop\n",
    "    return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start(in_dir , out_dir,img_class,frame_rate=500,resize=256):\n",
    "    # traverse whole directory\n",
    "    if not os.path.exists(out_dir):\n",
    "        os.makedirs(out_dir)\n",
    "    dir_list = []\n",
    "    for root, dirs, files in os.walk(f'{in_dir}'):\n",
    "        # select file name\n",
    "        for file in files:\n",
    "            # check the extension of files\n",
    "            if file.endswith('.mov'):\n",
    "                # print whole path of files\n",
    "                path = os.path.join(root, file)\n",
    "                # print(path)\n",
    "                dir_list.append(path)\n",
    "                # extractImages(path,'./data/train/real',frame_rate=15000)\n",
    "    count = extract_multiple_videos(dir_list,f'{out_dir}',img_class,frame_rate=frame_rate, resize=resize)\n",
    "    print(f'TOTAL FRAMES/IMAGES FORMED: {count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# START CAPTURING VIDEOS\n",
    "\n",
    "def extract_attack_multiple_videos(intput_filenames,pathOut,img_class,frame_rate, resize):\n",
    "    \"\"\"Extract video files into sequence of images.\n",
    "       Intput_filenames is a list for video file names\"\"\"\n",
    "\n",
    "    i = 0  # Counter of first video\n",
    "\n",
    "    # Iterate file names:\n",
    "    for intput_filename in intput_filenames:\n",
    "        print(\"Processing video:\", intput_filename)\n",
    "        img_name = 'client'\n",
    "        pattern = intput_filename.split('/')\n",
    "        for p in pattern:\n",
    "            if 'client' in p:\n",
    "                f_name = p.split('_')\n",
    "                for name in f_name:\n",
    "                    if name.find('client') != -1:\n",
    "                        img_name = name\n",
    "        \n",
    "        # print('the image will be named as:', img_name)\n",
    "        \n",
    "        \n",
    "        sec_count = 0\n",
    "        cap = cv2.VideoCapture(intput_filename)\n",
    "        cap.set(cv2.CAP_PROP_POS_MSEC,(sec_count*frame_rate))\n",
    "\n",
    "        # Keep iterating break\n",
    "        while True:\n",
    "            ret, frame = cap.read()  # Read frame from first video\n",
    "            if ret:\n",
    "                try:\n",
    "                    cropped_faces = extract_face(frame)\n",
    "                    cropped_faces = cv2.resize(cropped_faces,(resize,resize))\n",
    "                    write_path = pathOut + f'{img_name}_{i}_{img_class}.png'\n",
    "                    cv2.imwrite(write_path, cropped_faces)  # Write frame to JPEG file (1.jpg, 2.jpg, ...)\n",
    "                    i += 1 # Advance file counter\n",
    "                    sec_count += 1\n",
    "                except:\n",
    "                    pass\n",
    "            else:\n",
    "                # Break the interal loop when res status is False.\n",
    "                break\n",
    "\n",
    "            # cv2.waitKey(100) #Wait 100msec (for debugging)\n",
    "\n",
    "        cap.release() #Release must be inside the outer loop\n",
    "    return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_attack(in_dir , out_dir,img_class,frame_rate=500,resize=256):\n",
    "    # traverse whole directory\n",
    "    if not os.path.exists(out_dir):\n",
    "        os.makedirs(out_dir)\n",
    "    dir_list = []\n",
    "    for root, dirs, files in os.walk(f'{in_dir}'):\n",
    "        # select file name\n",
    "        for file in files:\n",
    "            # check the extension of files\n",
    "            if file.endswith('.mov'):\n",
    "                # print whole path of files\n",
    "                path = os.path.join(root, file)\n",
    "                # print(path)\n",
    "                dir_list.append(path)\n",
    "                # extractImages(path,'./data/train/real',frame_rate=15000)\n",
    "    count = extract_attack_multiple_videos(dir_list,f'{out_dir}',img_class,frame_rate=frame_rate, resize=resize)\n",
    "    print(f'TOTAL FRAMES/IMAGES FORMED: {count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRANSFORMING TRAINING VIDEOS TO TRAINING IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_real_vids_path = 'D:/BTP/dataset/Replay-Attack/train/real/'\n",
    "train_spoof_fixed_vids_path = 'D:/BTP/dataset/Reply-Attack/train/attack/fixed/'\n",
    "train_spoof_hand_vids_path = 'D:/BTP/dataset/Reply-Attack/train/attack/hand/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_real_imgs_path = './data/Replay-Attack-processed/train/real/'\n",
    "train_spoof_fixed_imgs_path = './data/Replay-Attack-processed/train/spoof/fixed/'\n",
    "train_spoof_hand_imgs_path = './data/Replay-Attack-processed/train/spoof/hand/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir_real = {\"in_dir\": train_real_vids_path,\"out_dir\":train_real_imgs_path}\n",
    "train_dir_attack_fixed = {\"in_dir\":train_spoof_fixed_vids_path, 'out_dir':train_spoof_fixed_imgs_path}\n",
    "train_dir_attack_hand = {\"in_dir\":train_spoof_hand_vids_path, 'out_dir':train_spoof_hand_imgs_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL FRAMES/IMAGES FORMED: 22490\n"
     ]
    }
   ],
   "source": [
    "start(train_dir_real['in_dir'],train_dir_real['out_dir'],img_class=\"real\",frame_rate=500,resize=256) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL FRAMES/IMAGES FORMED: 35436\n"
     ]
    }
   ],
   "source": [
    "start(train_dir_attack_fixed['in_dir'],train_dir_attack_fixed['out_dir'],img_class=\"attack_fixed\",frame_rate=500,resize=256) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL FRAMES/IMAGES FORMED: 33707\n"
     ]
    }
   ],
   "source": [
    "start(train_dir_attack_hand['in_dir'],train_dir_attack_hand['out_dir'],img_class=\"attack_hand\",frame_rate=500,resize=256) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRANSFORMING TEST VIDEOS TO TESTING IMAGES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_real_vids_path = 'D:/BTP/dataset/Replay-Attack/test/real/'\n",
    "test_spoof_fixed_vids_path = 'D:/BTP/dataset/Replay-Attack/test/attack/fixed/'\n",
    "test_spoof_hand_vids_path = 'D:/BTP/dataset/Replay-Attack/test/attack/hand/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_real_imgs_path = './data/Replay-Attack-processed/test/real/'\n",
    "test_spoof_fixed_imgs_path = './data/Replay-Attack-processed/test/spoof/fixed/'\n",
    "test_spoof_hand_imgs_path = './data/Replay-Attack-processed/test/spoof/hand/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir_real = {\"in_dir\": test_real_vids_path,\"out_dir\":test_real_imgs_path}\n",
    "test_dir_attack_fixed = {\"in_dir\":test_spoof_fixed_vids_path, 'out_dir':test_spoof_fixed_imgs_path}\n",
    "test_dir_attack_hand = {\"in_dir\":test_spoof_hand_vids_path, 'out_dir':test_spoof_hand_imgs_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL FRAMES/IMAGES FORMED: 29229\n"
     ]
    }
   ],
   "source": [
    "start(test_dir_real['in_dir'],test_dir_real['out_dir'],img_class=\"real\",frame_rate=2000,resize=256) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL FRAMES/IMAGES FORMED: 46700\n"
     ]
    }
   ],
   "source": [
    "start(test_dir_attack_fixed['in_dir'],test_dir_attack_fixed['out_dir'],img_class=\"attack_fixed\",frame_rate=500,resize=256) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL FRAMES/IMAGES FORMED: 44487\n"
     ]
    }
   ],
   "source": [
    "start(test_dir_attack_hand['in_dir'],test_dir_attack_hand['out_dir'],img_class=\"attack_hand\",frame_rate=500,resize=256) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data saved to train_data.csv\n",
      "Test data saved to test_data.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import csv\n",
    "\n",
    "# Define the paths to your train and test folders\n",
    "train_folder = './data/Replay-Attack-processed/train/'\n",
    "test_folder = './data/Replay-Attack-processed/test/'\n",
    "\n",
    "# Function to label and shuffle data in a folder\n",
    "def process_folder(folder_path, label):\n",
    "    image_paths = []\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.png'):\n",
    "                image_path = os.path.join(root, file)\n",
    "                image_paths.append((image_path, label))\n",
    "    \n",
    "    # Shuffle the image paths\n",
    "    random.shuffle(image_paths)\n",
    "    \n",
    "    return image_paths\n",
    "\n",
    "# Process the train and test folders\n",
    "train_real_paths = process_folder(os.path.join(train_folder, 'real'), 1)\n",
    "test_real_paths = process_folder(os.path.join(test_folder, 'real'), 1)\n",
    "\n",
    "# Include images from the \"hand\" and \"fixed\" subfolders within the \"spoof\" folder\n",
    "train_fake_paths = process_folder(os.path.join(train_folder, 'spoof/hand'), 0)\n",
    "train_fake_paths += process_folder(os.path.join(train_folder, 'spoof/fixed'), 0)\n",
    "\n",
    "test_fake_paths = process_folder(os.path.join(test_folder, 'spoof/hand'), 0)\n",
    "test_fake_paths += process_folder(os.path.join(test_folder, 'spoof/fixed'), 0)\n",
    "\n",
    "# Combine real and fake paths\n",
    "train_data = train_real_paths + train_fake_paths\n",
    "test_data = test_real_paths + test_fake_paths\n",
    "\n",
    "# Shuffle the combined data\n",
    "random.shuffle(train_data)\n",
    "random.shuffle(test_data)\n",
    "\n",
    "# Define CSV filenames\n",
    "train_csv_filename = 'train_data.csv'\n",
    "test_csv_filename = 'test_data.csv'\n",
    "\n",
    "# Write data to CSV files\n",
    "def write_to_csv(filename, data):\n",
    "    with open(filename, 'w', newline='') as csvfile:\n",
    "        csv_writer = csv.writer(csvfile)\n",
    "        csv_writer.writerow(['name', 'label'])\n",
    "        csv_writer.writerows(data)\n",
    "\n",
    "write_to_csv(train_csv_filename, train_data)\n",
    "write_to_csv(test_csv_filename, test_data)\n",
    "\n",
    "print(f\"Train data saved to {train_csv_filename}\")\n",
    "print(f\"Test data saved to {test_csv_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CHANGE DIRECTORY STRUCTURE BY PLACING IMAGES PERSON WISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_wise_dataset_train_path = './data/Reply-Attack-processed/train/images/' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dir_list(path):\n",
    "    dir_list = []\n",
    "    for root, dirs, files in os.walk(f'{path}'):\n",
    "        # select file name\n",
    "        for file in files:\n",
    "            # check the extension of files\n",
    "            if file.endswith('.png'):\n",
    "                # print whole path of files\n",
    "                path = os.path.join(root, file)\n",
    "                # print(path)\n",
    "                dir_list.append(path)\n",
    "    return dir_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22490\n",
      "35438\n",
      "33707\n"
     ]
    }
   ],
   "source": [
    "img_path_list_train_real = get_dir_list(train_real_imgs_path)\n",
    "img_path_list_train_spoof_fixed = get_dir_list(train_spoof_fixed_imgs_path)\n",
    "img_path_list_train_spoof_hand = get_dir_list(train_spoof_hand_imgs_path)\n",
    "print(len(img_path_list_train_real)) # ./replay-images/train/real/\n",
    "print(len(img_path_list_train_spoof_fixed)) # ./replay-images/train/spoof/fixed\n",
    "print(len(img_path_list_train_spoof_hand)) # ./replay-images/train/spoof/hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./data/Reply-Attack-processed/train/real/client001_0_real.png'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_path_list_train_real[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_client_objects(path_list):\n",
    "    clients = {}\n",
    "    for file in path_list:\n",
    "        path_parts = file.split('/')\n",
    "        for part in path_parts:\n",
    "            if 'client' in part:\n",
    "                file_name_split = part.split('_')\n",
    "                client_key = file_name_split[0]\n",
    "                if client_key in clients.keys():\n",
    "                    clients[client_key].append(file)\n",
    "                else:\n",
    "                    clients[client_key] = [file]\n",
    "    return clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_client_objects =  get_client_objects(img_path_list_train_real)\n",
    "spoof_fixed_client_objects = get_client_objects(img_path_list_train_spoof_fixed)\n",
    "spoof_hand_client_objects = get_client_objects(img_path_list_train_spoof_hand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['client001', 'client002', 'client004', 'client006', 'client007', 'client008', 'client012', 'client016', 'client018', 'client025', 'client027', 'client103', 'client105', 'client108', 'client110']\n",
      "['client001', 'client002', 'client004', 'client006', 'client007', 'client008', 'client012', 'client016', 'client018', 'client025', 'client027', 'client103', 'client105', 'client108', 'client110']\n",
      "['client001', 'client002', 'client004', 'client006', 'client007', 'client008', 'client012', 'client016', 'client018', 'client025', 'client027', 'client103', 'client105', 'client108', 'client110']\n"
     ]
    }
   ],
   "source": [
    "print(sorted(real_client_objects.keys()))\n",
    "print(sorted(spoof_fixed_client_objects.keys()))\n",
    "print(sorted(spoof_hand_client_objects.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_wise_dir_list = get_dir_list(person_wise_dataset_train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "person_wise_dir_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " DataGeneration.ipynb                              \u001b[0m\u001b[01;34mreplay-dummy-person-wise\u001b[0m/\r\n",
      " \u001b[01;34mdataset\u001b[0m/                                          \u001b[01;34mreplay-images\u001b[0m/\r\n",
      " haarcascade_frontalface_default.xml               \u001b[01;35mtest_img.png\u001b[0m\r\n",
      "'PIxel Wise Supervision - Siamese-Network.ipynb'\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREATE list.txt AND APPEND FORMATED PATHS OF IMAGES TO IT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/Reply-Attack-processed/train/list.txt', 'w') as f:\n",
    "    for path in person_wise_dir_list:\n",
    "        if '/data/Reply-Attack-processed/train/images/' in path:\n",
    "            s = path.split('/data/Reply-Attack-processed/train/images/')\n",
    "            p = s[1]\n",
    "            f.write(\"%s\\n\" % p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: './data/Reply-Attack-processed/train/images/client001'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\BTP\\maincode\\replay-attack-processing.ipynb Cell 41\u001b[0m in \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/BTP/maincode/replay-attack-processing.ipynb#X45sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     shutil\u001b[39m.\u001b[39mrmtree(person_wise_dataset_train_path\u001b[39m+\u001b[39mclient_key)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/BTP/maincode/replay-attack-processing.ipynb#X45sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m single_client_path \u001b[39m=\u001b[39m person_wise_dataset_train_path\u001b[39m+\u001b[39mclient_key\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/BTP/maincode/replay-attack-processing.ipynb#X45sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m os\u001b[39m.\u001b[39;49mmkdir(single_client_path)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/BTP/maincode/replay-attack-processing.ipynb#X45sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m single_client_path_real \u001b[39m=\u001b[39m single_client_path \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/real\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/BTP/maincode/replay-attack-processing.ipynb#X45sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m single_client_path_spoof \u001b[39m=\u001b[39m single_client_path \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/spoof\u001b[39m\u001b[39m'\u001b[39m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: './data/Reply-Attack-processed/train/images/client001'"
     ]
    }
   ],
   "source": [
    "for client_key in sorted(real_client_objects.keys()):\n",
    "    if os.path.isdir(person_wise_dataset_train_path+client_key):\n",
    "        shutil.rmtree(person_wise_dataset_train_path+client_key)\n",
    "    single_client_path = person_wise_dataset_train_path+client_key\n",
    "    os.mkdir(single_client_path)\n",
    "    \n",
    "    single_client_path_real = single_client_path + '/real'\n",
    "    single_client_path_spoof = single_client_path + '/spoof'\n",
    "    os.mkdir(single_client_path_real)\n",
    "    os.mkdir(single_client_path_spoof)\n",
    "    for raw_client_image_path in real_client_objects[client_key]:\n",
    "        shutil.copy2(raw_client_image_path,single_client_path_real)\n",
    "    for raw_client_image_path in spoof_fixed_client_objects[client_key]:\n",
    "        shutil.copy2(raw_client_image_path,single_client_path_spoof)\n",
    "    for raw_client_image_path in spoof_hand_client_objects[client_key]:\n",
    "        shutil.copy2(raw_client_image_path,single_client_path_spoof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
